{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport os \nimport cv2 \nfrom glob import glob\nimport torchvision.models as models\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:02.724543Z","iopub.execute_input":"2022-03-20T04:39:02.724984Z","iopub.status.idle":"2022-03-20T04:39:02.730381Z","shell.execute_reply.started":"2022-03-20T04:39:02.724940Z","shell.execute_reply":"2022-03-20T04:39:02.729684Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dir_Flickr_jpg = \"../input/d/datasets/nunenuh/flickr8k/images\"\ndir_Flickr_text = \"../input/d/datasets/nunenuh/flickr8k/captions.txt\"\n\njpgs = os.listdir(dir_Flickr_jpg)\nprint(\"The number of jpg flies in Flicker8k: {}\".format(len(jpgs)))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:02.920232Z","iopub.execute_input":"2022-03-20T04:39:02.921774Z","iopub.status.idle":"2022-03-20T04:39:02.943258Z","shell.execute_reply.started":"2022-03-20T04:39:02.921731Z","shell.execute_reply":"2022-03-20T04:39:02.942405Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"file = open(dir_Flickr_text,'r')\ntext = file.read()\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:03.059310Z","iopub.execute_input":"2022-03-20T04:39:03.059519Z","iopub.status.idle":"2022-03-20T04:39:03.072163Z","shell.execute_reply.started":"2022-03-20T04:39:03.059495Z","shell.execute_reply":"2022-03-20T04:39:03.068248Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_doc(filename):\n    open_file = open(dir_Flickr_text, 'r', encoding='latin-1' ) \n    text = open_file.read() \n    open_file.close()\n    return text\ndoc = load_doc(text)\nprint(doc[:300])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:03.167624Z","iopub.execute_input":"2022-03-20T04:39:03.168076Z","iopub.status.idle":"2022-03-20T04:39:03.178219Z","shell.execute_reply.started":"2022-03-20T04:39:03.168043Z","shell.execute_reply":"2022-03-20T04:39:03.177120Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"all_img_id = [] \nall_img_vector = [] \nannotations = [] \n\nwith open(dir_Flickr_text , 'r') as fo:\n  next(fo) \n  for line in fo :\n    split_arr = line.split('|')\n    all_img_id.append(split_arr[0])\n    annotations.append(split_arr[2].rstrip('\\n')) #removing out the \\n.\n    all_img_vector.append(split_arr[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:03.793322Z","iopub.execute_input":"2022-03-20T04:39:03.794129Z","iopub.status.idle":"2022-03-20T04:39:03.852401Z","shell.execute_reply.started":"2022-03-20T04:39:03.794082Z","shell.execute_reply":"2022-03-20T04:39:03.851716Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_txt = pd.DataFrame(list(zip(all_img_id, all_img_vector,annotations)),columns =['filename','Index', 'caption']) \nuni_filenames = np.unique(df_txt.values)   \ndf_txt.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:03.943599Z","iopub.execute_input":"2022-03-20T04:39:03.943913Z","iopub.status.idle":"2022-03-20T04:39:04.133930Z","shell.execute_reply.started":"2022-03-20T04:39:03.943858Z","shell.execute_reply":"2022-03-20T04:39:04.133218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Text","metadata":{}},{"cell_type":"code","source":"def df_word(df_txt):\n    vocabulary = []\n    for txt in df_txt.caption.values:\n        vocabulary.extend(txt.split())\n    print('Vocabulary Size: %d' % len(set(vocabulary)))\n    ct = Counter(vocabulary)\n    dfword = pd.DataFrame(list(ct.items()), columns=['word', 'count'])\n    dfword.sort_values(by='count', ascending=False, inplace=True)\n    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n    return(dfword)\ndfword = df_word(df_txt)\ndfword.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:05.321352Z","iopub.execute_input":"2022-03-20T04:39:05.321785Z","iopub.status.idle":"2022-03-20T04:39:05.492103Z","shell.execute_reply.started":"2022-03-20T04:39:05.321744Z","shell.execute_reply":"2022-03-20T04:39:05.491391Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import string\n\ndef remove_punctuation(text_original):\n    text_no_punctuation = text_original.translate(str.maketrans('','',string.punctuation))\n    return(text_no_punctuation)\n\n\ndef remove_single_character(text):\n    text_len_more_than1 = \"\"\n    for word in text.split():\n        if len(word) > 1:\n            text_len_more_than1 += \" \" + word\n    return(text_len_more_than1)\n\n\ndef remove_numeric(text,printTF=False):\n    text_no_numeric = \"\"\n    for word in text.split():\n        isalpha = word.isalpha()\n        if printTF:\n            print(\"    {:10} : {:}\".format(word,isalpha))\n        if isalpha:\n            text_no_numeric += \" \" + word\n    return(text_no_numeric)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:05.518350Z","iopub.execute_input":"2022-03-20T04:39:05.519010Z","iopub.status.idle":"2022-03-20T04:39:05.525949Z","shell.execute_reply.started":"2022-03-20T04:39:05.518975Z","shell.execute_reply":"2022-03-20T04:39:05.525121Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def text_clean(text_original):\n    text = remove_punctuation(text_original)\n    text = remove_single_character(text)\n    text = remove_numeric(text)\n    return(text)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:06.346572Z","iopub.execute_input":"2022-03-20T04:39:06.347104Z","iopub.status.idle":"2022-03-20T04:39:06.351493Z","shell.execute_reply.started":"2022-03-20T04:39:06.347065Z","shell.execute_reply":"2022-03-20T04:39:06.350415Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for i, caption in enumerate(df_txt.caption.values):\n    newcaption = text_clean(caption)\n    df_txt[\"caption\"].iloc[i] = newcaption","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:06.526782Z","iopub.execute_input":"2022-03-20T04:39:06.527314Z","iopub.status.idle":"2022-03-20T04:39:18.856148Z","shell.execute_reply.started":"2022-03-20T04:39:06.527267Z","shell.execute_reply":"2022-03-20T04:39:18.855421Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from copy import copy\ndef add_start_end_seq_token(caption):\n    caps = []\n    for txt in caption:\n        txt = 'startseq ' + txt + ' endseq'\n        caps.append(txt)\n    return(caps)\ndf_txt0 = copy(df_txt)\ndf_txt0[\"caption\"] = add_start_end_seq_token(df_txt[\"caption\"])\ndf_txt0.head(5)\ndel df_txt","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:18.857765Z","iopub.execute_input":"2022-03-20T04:39:18.858038Z","iopub.status.idle":"2022-03-20T04:39:18.883891Z","shell.execute_reply.started":"2022-03-20T04:39:18.858004Z","shell.execute_reply":"2022-03-20T04:39:18.883267Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_txt0.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:21.369150Z","iopub.execute_input":"2022-03-20T04:39:21.369417Z","iopub.status.idle":"2022-03-20T04:39:21.378972Z","shell.execute_reply.started":"2022-03-20T04:39:21.369386Z","shell.execute_reply":"2022-03-20T04:39:21.378283Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodelvgg = tf.keras.applications.VGG16(include_top=True, weights=None)\nmodelvgg.load_weights(\"../input/weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\")\nmodelvgg.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:41:31.748288Z","iopub.execute_input":"2022-03-20T04:41:31.748874Z","iopub.status.idle":"2022-03-20T04:41:45.460356Z","shell.execute_reply.started":"2022-03-20T04:41:31.748781Z","shell.execute_reply":"2022-03-20T04:41:45.459631Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"modelvgg.layers.pop()\nmodelvgg = tf.keras.Model(inputs=modelvgg.inputs, outputs=modelvgg.layers[-2].output)\nmodelvgg.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:41:48.541064Z","iopub.execute_input":"2022-03-20T04:41:48.541562Z","iopub.status.idle":"2022-03-20T04:41:48.561788Z","shell.execute_reply.started":"2022-03-20T04:41:48.541525Z","shell.execute_reply":"2022-03-20T04:41:48.561088Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom collections import OrderedDict\nfrom tqdm import tqdm\n\n\n\njpgs = os.listdir(dir_Flickr_jpg)\nimages = OrderedDict()\nnpix = 224\ntarget_size = (npix,npix,3)\ndata = np.zeros((len(jpgs),npix,npix,3))\nfor i,name in enumerate(tqdm(jpgs)):\n    \n    filename = dir_Flickr_jpg + '/' + name\n    image = load_img(filename, target_size=target_size)\n    image = img_to_array(image)\n    nimage = preprocess_input(image)\n    \n    y_pred = modelvgg.predict(nimage.reshape( (1,) + nimage.shape[:3]))\n    images[name] = y_pred.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T04:39:25.117930Z","iopub.status.idle":"2022-03-20T04:39:25.118700Z","shell.execute_reply.started":"2022-03-20T04:39:25.118467Z","shell.execute_reply":"2022-03-20T04:39:25.118496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images[\"1000268201_693b08cb0e.jpg\"].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:36:25.852392Z","iopub.execute_input":"2022-03-20T03:36:25.85306Z","iopub.status.idle":"2022-03-20T03:36:25.858372Z","shell.execute_reply.started":"2022-03-20T03:36:25.853019Z","shell.execute_reply":"2022-03-20T03:36:25.857577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(images)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:38:03.621866Z","iopub.execute_input":"2022-03-20T03:38:03.622115Z","iopub.status.idle":"2022-03-20T03:38:03.628915Z","shell.execute_reply.started":"2022-03-20T03:38:03.622088Z","shell.execute_reply":"2022-03-20T03:38:03.628104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_txt0.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:38:32.254168Z","iopub.execute_input":"2022-03-20T03:38:32.254427Z","iopub.status.idle":"2022-03-20T03:38:32.266738Z","shell.execute_reply.started":"2022-03-20T03:38:32.254398Z","shell.execute_reply":"2022-03-20T03:38:32.265983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dimages, keepindex = [],[]\ndf_txt0 = df_txt0.loc[df_txt0[\"Index\"].values == \"0\",: ]\nfor i, fnm in enumerate(df_txt0.filename):\n    if fnm in images.keys():\n        dimages.append(images[fnm])\n        keepindex.append(i)\n        \nfnames = df_txt0[\"filename\"].iloc[keepindex].values\ndcaptions = df_txt0[\"caption\"].iloc[keepindex].values\ndimages = np.array(dimages)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:38:36.78145Z","iopub.execute_input":"2022-03-20T03:38:36.781759Z","iopub.status.idle":"2022-03-20T03:38:36.864018Z","shell.execute_reply.started":"2022-03-20T03:38:36.781725Z","shell.execute_reply":"2022-03-20T03:38:36.863289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dimages.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:38:49.778329Z","iopub.execute_input":"2022-03-20T03:38:49.778871Z","iopub.status.idle":"2022-03-20T03:38:49.785997Z","shell.execute_reply.started":"2022-03-20T03:38:49.778832Z","shell.execute_reply":"2022-03-20T03:38:49.785111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dcaptions[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:03.299587Z","iopub.execute_input":"2022-03-20T03:39:03.299834Z","iopub.status.idle":"2022-03-20T03:39:03.305089Z","shell.execute_reply.started":"2022-03-20T03:39:03.299807Z","shell.execute_reply":"2022-03-20T03:39:03.304162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\nnb_words = 8000\ntokenizer = Tokenizer(nb_words=nb_words)\ntokenizer.fit_on_texts(dcaptions)\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"vocabulary size : {}\".format(vocab_size))\ndtexts = tokenizer.texts_to_sequences(dcaptions)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:45:58.940662Z","iopub.execute_input":"2022-03-20T03:45:58.940918Z","iopub.status.idle":"2022-03-20T03:45:59.172663Z","shell.execute_reply.started":"2022-03-20T03:45:58.94089Z","shell.execute_reply":"2022-03-20T03:45:59.171875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtexts[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:46:06.510329Z","iopub.execute_input":"2022-03-20T03:46:06.510627Z","iopub.status.idle":"2022-03-20T03:46:06.518059Z","shell.execute_reply.started":"2022-03-20T03:46:06.510595Z","shell.execute_reply":"2022-03-20T03:46:06.517172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prop_test, prop_val = 0.2, 0.2\n\nN = len(dtexts)\nNtest, Nval = int(N*prop_test), int(N*prop_val)\n\ndef split_test_val_train(dtexts,Ntest,Nval):\n    return(dtexts[:Ntest], \n           dtexts[Ntest:Ntest+Nval],  \n           dtexts[Ntest+Nval:])\n\ndt_test,  dt_val, dt_train   = split_test_val_train(dtexts,Ntest,Nval)\ndi_test,  di_val, di_train   = split_test_val_train(dimages,Ntest,Nval)\nfnm_test,fnm_val, fnm_train  = split_test_val_train(fnames,Ntest,Nval)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:46:19.345169Z","iopub.execute_input":"2022-03-20T03:46:19.345432Z","iopub.status.idle":"2022-03-20T03:46:19.353013Z","shell.execute_reply.started":"2022-03-20T03:46:19.345403Z","shell.execute_reply":"2022-03-20T03:46:19.352034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen = np.max([len(text) for text in dtexts])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:46:27.357789Z","iopub.execute_input":"2022-03-20T03:46:27.358053Z","iopub.status.idle":"2022-03-20T03:46:27.364742Z","shell.execute_reply.started":"2022-03-20T03:46:27.358026Z","shell.execute_reply":"2022-03-20T03:46:27.363747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\ndef preprocessing(dtexts,dimages):\n    N = len(dtexts)\n    print(\"# captions/images = {}\".format(N))\n\n    assert(N==len(dimages))\n    Xtext, Ximage, ytext = [],[],[]\n    for text,image in zip(dtexts,dimages):\n\n        for i in range(1,len(text)):\n            in_text, out_text = text[:i], text[i]\n            in_text = pad_sequences([in_text],maxlen=maxlen).flatten()\n            out_text = to_categorical(out_text,num_classes = vocab_size)\n\n            Xtext.append(in_text)\n            Ximage.append(image)\n            ytext.append(out_text)\n\n    Xtext  = np.array(Xtext)\n    Ximage = np.array(Ximage)\n    ytext  = np.array(ytext)\n    print(\" {} {} {}\".format(Xtext.shape,Ximage.shape,ytext.shape))\n    return(Xtext,Ximage,ytext)\n\n\nXtext_train, Ximage_train, ytext_train = preprocessing(dt_train,di_train)\nXtext_val,   Ximage_val,   ytext_val   = preprocessing(dt_val,di_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:47:12.294987Z","iopub.execute_input":"2022-03-20T03:47:12.295369Z","iopub.status.idle":"2022-03-20T03:47:15.900008Z","shell.execute_reply.started":"2022-03-20T03:47:12.295337Z","shell.execute_reply":"2022-03-20T03:47:15.899139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtext_train[:14]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:47:27.312642Z","iopub.execute_input":"2022-03-20T03:47:27.312893Z","iopub.status.idle":"2022-03-20T03:47:27.321856Z","shell.execute_reply.started":"2022-03-20T03:47:27.312866Z","shell.execute_reply":"2022-03-20T03:47:27.321196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ximage_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:47:33.47905Z","iopub.execute_input":"2022-03-20T03:47:33.479303Z","iopub.status.idle":"2022-03-20T03:47:33.484396Z","shell.execute_reply.started":"2022-03-20T03:47:33.479275Z","shell.execute_reply":"2022-03-20T03:47:33.483606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytext_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:47:41.440494Z","iopub.execute_input":"2022-03-20T03:47:41.441055Z","iopub.status.idle":"2022-03-20T03:47:41.447053Z","shell.execute_reply.started":"2022-03-20T03:47:41.441014Z","shell.execute_reply":"2022-03-20T03:47:41.446088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nprint(vocab_size)\n## image feature\n\ndim_embedding = 64\n\ninput_image = layers.Input(shape=(Ximage_train.shape[1],))\nfimage = layers.Dense(256,activation='relu',name=\"ImageFeature\")(input_image)\n\n## sequence model\ninput_txt = layers.Input(shape=(maxlen,))\n### The embedding layer in Keras can be used when we want to create the embeddings to embed higher dimensional data into lower dimensional vector space.\nftxt = layers.Embedding(vocab_size,dim_embedding, mask_zero=True)(input_txt)\nftxt = layers.LSTM(256,name=\"CaptionFeature\")(ftxt)\n\n## combined model for decoder\ndecoder = layers.add([ftxt,fimage])\ndecoder = layers.Dense(256,activation='relu')(decoder)\noutput = layers.Dense(vocab_size,activation='softmax')(decoder)\nmodel = tf.keras.Model(inputs=[input_image, input_txt],outputs=output)\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:47:52.44454Z","iopub.execute_input":"2022-03-20T03:47:52.445079Z","iopub.status.idle":"2022-03-20T03:47:53.237912Z","shell.execute_reply.started":"2022-03-20T03:47:52.44504Z","shell.execute_reply":"2022-03-20T03:47:53.237099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Ximage_train[0])\nprint(Xtext_train[0])\nprint(ytext_train[0][75])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:48:02.684129Z","iopub.execute_input":"2022-03-20T03:48:02.684404Z","iopub.status.idle":"2022-03-20T03:48:02.69097Z","shell.execute_reply.started":"2022-03-20T03:48:02.684374Z","shell.execute_reply":"2022-03-20T03:48:02.690101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart = time.time()\n\nhist = model.fit([Ximage_train, Xtext_train], ytext_train, \n                  epochs=5, verbose=2, \n                  batch_size=64,\n                  validation_data=([Ximage_val, Xtext_val], ytext_val))\n    \nend = time.time()\nprint(\"TIME TOOK {:3.2f}MIN\".format((end - start )/60))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:48:15.440059Z","iopub.execute_input":"2022-03-20T03:48:15.440634Z","iopub.status.idle":"2022-03-20T03:54:03.271235Z","shell.execute_reply.started":"2022-03-20T03:48:15.440594Z","shell.execute_reply":"2022-03-20T03:54:03.2705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for label in [\"loss\",\"val_loss\"]:\n    plt.plot(hist.history[label],label=label)\nplt.legend()\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:54:03.272897Z","iopub.execute_input":"2022-03-20T03:54:03.273225Z","iopub.status.idle":"2022-03-20T03:54:03.479905Z","shell.execute_reply.started":"2022-03-20T03:54:03.273185Z","shell.execute_reply":"2022-03-20T03:54:03.479253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_word = dict([(index,word) for word, index in tokenizer.word_index.items()])\ndef predict_caption(image):\n    '''\n    image.shape = (1,4462)\n    '''\n\n    in_text = 'startseq'\n\n    for iword in range(maxlen):\n        sequence = tokenizer.texts_to_sequences([in_text])[0]\n        sequence = pad_sequences([sequence],maxlen)\n        yhat = model.predict([image,sequence],verbose=0)\n        yhat = np.argmax(yhat)\n        newword = index_word[yhat]\n        in_text += \" \" + newword\n        if newword == \"endseq\":\n            break\n    return(in_text)\n\n\n\nnpic = 5\nnpix = 224\ntarget_size = (npix,npix,3)\n\ncount = 1\nfig = plt.figure(figsize=(10,20))\nfor jpgfnm, image_feature in zip(fnm_test[:npic],di_test[:npic]):\n    ## images \n    filename = dir_Flickr_jpg + '/' + jpgfnm\n    image_load = load_img(filename, target_size=target_size)\n    ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n    ax.imshow(image_load)\n    count += 1\n\n    ## captions\n    caption = predict_caption(image_feature.reshape(1,len(image_feature)))\n    ax = fig.add_subplot(npic,2,count)\n    plt.axis('off')\n    ax.plot()\n    ax.set_xlim(0,1)\n    ax.set_ylim(0,1)\n    ax.text(0,0.5,caption,fontsize=20)\n    count += 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:54:03.481093Z","iopub.execute_input":"2022-03-20T03:54:03.481334Z","iopub.status.idle":"2022-03-20T03:54:07.115565Z","shell.execute_reply.started":"2022-03-20T03:54:03.481299Z","shell.execute_reply":"2022-03-20T03:54:07.114915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}